<p align="center">
  <img src="https://raw.githubusercontent.com/dbt-labs/dbt-core/fa1ea14ddfb1d5ae319d5141844910dd53ab2834/etc/dbt-core.svg" alt="dbt logo" width="750"/>
</p>

<h1 align="center">DBT Docker Template â€“ BigQuery | Redshift | Snowflake | Postgres</h1>

<p align="center">
  <b>Modular, production-ready DBT project for BigQuery, Redshift, and Postgres.</b><br>
  Easily build, deploy, and run DBT models in Dockerized CI/CD pipelines across cloud and local environments.
</p>

<!-- <p align="center">
  <a href="https://github.com/themani-dev/dbt-core/actions/workflows/main.yml">
    <img src="https://github.com/themani-dev//actions/workflows/main.yml/badge.svg?event=push" alt="CI Badge"/>
  </a>
</p> -->

<p align="center">

  <a href="#quickstart-for-gcp-bigquery">
    <img src="https://img.shields.io/badge/BigQuery%20Setup-GCP-blue?style=for-the-badge&logo=googlecloud&logoColor=white" alt="BigQuery Badge"/>
  </a>
  &nbsp;
  <a href="#-quickstart-for-aws-redshift">
    <img src="https://img.shields.io/badge/Redshift%20Setup-AWS-orange?style=for-the-badge&logo=amazonaws&logoColor=white" alt="Redshift Badge"/>
  </a>
  &nbsp;
  <a href="#-quickstart-for-postgres-vmonprem">
    <img src="https://img.shields.io/badge/Postgres%20Setup-OnPrem%2FLocal-316192?style=for-the-badge&logo=postgresql&logoColor=white" alt="Postgres Badge"/>
  </a>
  &nbsp;
  <a href="#-quickstart-for-snowflake">
    <img src="https://img.shields.io/badge/Snowflake%20Setup-Cross--Cloud-00c7e6?style=for-the-badge&logo=snowflake&logoColor=white" alt="Snowflake Badge"/>
  </a>

</p>


---
## ğŸ“Œ Project Status

> ğŸš§ **This project is currently a Work In Progress (WIP).**  
> While the structure and components are functional, some environments are still under development:

| Environment | Status           | Notes                        |
|-------------|------------------|------------------------------|
| BigQuery    | âœ… Complete       | Includes Cloud Build, wrapper, and Dockerfile |
| Redshift    | ğŸ”§ In Progress    | Dockerfile and profile ready |
| Snowflake   | ğŸ”§ In Progress    | Profile planned              |
| Postgres    | ğŸ”§ In Progress    | Docker build supported       |

---

## ğŸ¯ Project Goal

This repository is intended to deliver a **production-ready DBT Docker image** with consistent structure and flexible environment support for the following services:

- âœ… **BigQuery** â€“ GCP-native, with Cloud Build CI/CD
- âœ… **Redshift** â€“ AWS-native, ready for ECR/Batch
- âœ… **Snowflake** â€“ Cross-cloud analytics support
- âœ… **Postgres** â€“ Local or on-premise development setups

Each environment is supported through:
- âœ… Custom `profiles.yml`
- âœ… Dedicated folder under `framework/`
- âœ… Docker image build support via `--build-arg`
- âœ… Centralized orchestration via wrapper scripts
- CI/CD automation for:
  - âœ… GCP Cloud Build (`framework/bigquery/cloudbuild.yaml`)


---

## ğŸ—‚ï¸ Project Structure

<details open>
<summary><strong>ğŸ“‚ Click to close full project structure</strong></summary>

```bash
.
â”œâ”€â”€ ğŸ“„ Dockerfile                  # Build DBT image with chosen adapter (bigquery/redshift/postgres)
â”œâ”€â”€ ğŸ“„ bigquery_wrapper.sh        # Shell script to build & push DBT image to GCP Artifact Registry
â”œâ”€â”€ ğŸ“ framework/                 # Environment-specific DBT projects
â”‚   â””â”€â”€ ğŸ“ bigquery/              # DBT project using BigQuery adapter
â”‚       â”œâ”€â”€ ğŸ“„ dbt_project.yml    # Main DBT project config
â”‚       â”œâ”€â”€ ğŸ“„ cloudbuild.yaml    # GCP Cloud Build config for CI/CD pipeline
â”‚       â”œâ”€â”€ ğŸ“ models/            # DBT models organized by transformation layer
â”‚       â”‚   â”œâ”€â”€ ğŸ“ raw/           # Raw layer â€” source tables
â”‚       â”‚   â”‚   â””â”€â”€ ğŸ“„ sources.yml
â”‚       â”‚   â”œâ”€â”€ ğŸ“ curated/       # Curated layer â€” cleaned, transformed data
â”‚       â”‚   â”‚   â”œâ”€â”€ ğŸ“„ schema.yml
â”‚       â”‚   â”‚   â””â”€â”€ ğŸ“„ tbl_curated.sql
â”‚       â”‚   â”œâ”€â”€ ğŸ“ semantic/      # Semantic layer â€” facts/dimensions
â”‚       â”‚   â”‚   â”œâ”€â”€ ğŸ“„ schema.yml
â”‚       â”‚   â”‚   â”œâ”€â”€ ğŸ“„ tbl_semantic.sql
â”‚       â”‚   â””â”€â”€ ğŸ“ consumption/   # Consumption layer â€” final outputs for BI
â”‚       â”‚       â””â”€â”€ ğŸ“„ schema.yml
â”‚       â”œâ”€â”€ ğŸ“ analyses/          # (Optional) Deep dive SQL analysis
â”‚       â”œâ”€â”€ ğŸ“ macros/            # Custom Jinja macros
â”‚       â”œâ”€â”€ ğŸ“ seeds/             # Seed data for static reference tables
â”‚       â”œâ”€â”€ ğŸ“ snapshots/         # DBT snapshots for slowly changing dimensions
â”‚       â””â”€â”€ ğŸ“ tests/             # Custom DBT tests
â”œâ”€â”€ ğŸ“ profiles/                  # DBT profiles for different backends
â”‚   â”œâ”€â”€ ğŸ“„ profiles_bigquery.yml  # BigQuery profile â€” update project, dataset, keyfile
â”‚   â”œâ”€â”€ ğŸ“„ profiles_redshift.yml  # Redshift profile for AWS
â”‚   â”œâ”€â”€ ğŸ“„ profiles_postgres.yml  # Postgres profile for on-prem/dev
â”‚   â””â”€â”€ ğŸ“„ profiles_snowflake.yml # (Optional) profile for Snowflake
â”œâ”€â”€ ğŸ“ serviceAccounts/
â”‚   â””â”€â”€ ğŸ“„ gcloud.json            # GCP service account key file (used in Dockerfile)
â””â”€â”€ ğŸ“„ README.md                  # You're looking at it ğŸ˜‰
````
</details> 



---
# ğŸš€ Step-by-Step Deployment Guide

### Prerequisites

Ensure you have the following tools installed:
- [Docker](https://www.docker.com/get-started)
- A terminal with Docker access


## Quickstart for GCP (BigQuery)


### 1. ğŸ” Update Service Account (Optional)

If youâ€™re using **Service Account JSON**:

- Replace the contents of `serviceAccounts/gcloud.json` with your GCP service account key.
- Ensure it has permissions for **BigQuery Admin**, **Cloud Storage Viewer**, etc.

---

### 2. âš™ï¸ Update `profiles_bigquery.yml`

Manually update project-specific values in:
```yaml
project: "your-gcp-project"
dataset: "your_dataset"
keyfile: "/app/gcloud.json"
location: "US"
```
### 3. ğŸ—ï¸ Set Up Artifact Registry

- In GCP Console â†’ Artifact Registry â†’ Create Docker repo
- Example: us-west2-docker.pkg.dev/your-project/dataengineering/dbt

### 4. ğŸ“œ Use the Wrapper Script to Build + Push
```bash
chmod +x bigquery_wrapper.sh
./bigquery_wrapper.sh
```
This script will:

- Build the Docker image with BigQuery adapter

- Tag it for Artifact Registry

- Push it to GCP Artifact Registery

### 5. âœ… Confirm Upload
Check in GCP Console â†’ Artifact Registry â†’ dbt:latest image is visible.


## ğŸš§ Quickstart for AWS (Redshift)
> coming soon
## ğŸš§ Quickstart for postgres (vm/onprem)
> coming soon
## ğŸš§ Quickstart for snowflake
> coming soon
---
## ğŸ“‚ Profiles Support
Each profile (`profiles_<adapter>.yml`) supports multiple authentication methods and project targets. Example for BigQuery:

```yaml
keyfile: "/app/gcloud.json"
project: "your-gcp-project"
dataset: "your_dataset"
```
You can also use env_var() if you later adopt environment-based configuration.

---
## **ğŸ”§ Contributions**

Pull requests are welcome! Suggested contributions:

- AWS ECR + Batch CI/CD

- Secrets Manager integration

- MWAA-ready DAGs

---
## ğŸ“« Maintainer
Manikanta Reddy Kallam

ğŸ“§ `themanidev@gmail.com`

ğŸŒ https://themani.dev